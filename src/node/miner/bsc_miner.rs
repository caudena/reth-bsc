use crate::{
    consensus::parlia::provider::SnapshotProvider,
    node::{
        engine::BscBuiltPayload,
        evm::config::BscEvmConfig,
        miner::{
            payload_builder::BscPayloadBuilder, 
            util::prepare_new_attributes, 
            signer::init_global_signer,
            config::{keystore, MiningConfig}
        },
    },
    BscBlock,
};
use alloy_consensus::BlockHeader;
use alloy_primitives::{Address, B256};
use k256::ecdsa::SigningKey;
use reth::transaction_pool::PoolTransaction;
use reth::transaction_pool::TransactionPool;
use reth_ethereum_payload_builder::EthereumBuilderConfig;
use reth_payload_primitives::BuiltPayload;
use reth_primitives::{SealedBlock, TransactionSigned};
use reth_provider::{BlockNumReader, HeaderProvider, CanonStateSubscriptions, CanonStateNotification};
use std::sync::Arc;
use std::time::{SystemTime, UNIX_EPOCH};
use tokio::sync::mpsc;
use tokio_stream::StreamExt;
use tracing::{debug, error, info, warn};
use reth_tasks::TaskExecutor;
use reth_basic_payload_builder::{BuildArguments, PayloadConfig};
use reth::payload::EthPayloadBuilderAttributes;
use reth_revm::cancelled::CancelOnDrop;
use reth_primitives_traits::BlockBody;
use crate::node::network::BscNewBlock;
use crate::shared::{get_block_import_sender, get_local_peer_id_or_default};
use alloy_primitives::U128;
use reth_network::message::NewBlockMessage;

pub struct MiningContext {
    parent_header: reth_primitives::SealedHeader,
    parent_snapshot: Arc<crate::consensus::parlia::snapshot::Snapshot>,
}

/// NewWorkWorker responsible for listening to canonical state changes and triggering mining.
pub struct NewWorkWorker<Provider> {
    validator_address: Address,
    provider: Provider,
    snapshot_provider: Arc<dyn SnapshotProvider + Send + Sync>,
    mining_queue_tx: mpsc::UnboundedSender<MiningContext>,
}

impl<Provider> NewWorkWorker<Provider> 
where
    Provider: HeaderProvider<Header = alloy_consensus::Header>
        + BlockNumReader
        + reth_provider::StateProviderFactory
        + CanonStateSubscriptions
        + reth_provider::NodePrimitivesProvider
        + Clone
        + Send
        + Sync
        + 'static,
{
    pub fn new(
        validator_address: Address,
        provider: Provider,
        snapshot_provider: Arc<dyn SnapshotProvider + Send + Sync>,
        mining_queue_tx: mpsc::UnboundedSender<MiningContext>,
    ) -> Self {
        Self {
            validator_address,
            provider,
            snapshot_provider,
            mining_queue_tx,
        }
    }

    pub async fn run(self) {
        info!("Succeed to spawn new work worker, address: {}", self.validator_address);
        let mut notifications = self.provider.canonical_state_stream();
        
        loop {
            tokio::select! {
                notification = notifications.next() => {
                    match notification {
                        Some(event) => {
                            self.try_new_work(event.clone()).await;
                        }
                        None => {
                            warn!("Canonical state notification stream ended, exiting...");
                            break;
                        }
                    }
                }
            }
        }
    }

    async fn try_new_work(&self, new_state: CanonStateNotification<Provider::Primitives>) {
        // todo: refine it as pre cache to speedup, committed.execution_outcome().
        let committed = new_state.committed();
        let tip = committed.tip();
        debug!(
            "try new work, tip_block={}, committed_blocks={}",
            committed.tip().number(),
            committed.len()
        );
        
        // todo: refine check is_syncing status.
        if tip.timestamp() < SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs() - 3 {
            debug!("Skip to mine new block due to maybe in syncing, validator: {}, tip: {}", self.validator_address, tip.number());
            return;
        }
        
        let parent_header = match self.provider.sealed_header(tip.number()) {
            Ok(Some(header)) => header,
            Ok(None) => {
                debug!("Skip to mine new block due to head block header not found, validator: {}, tip: {}", self.validator_address, tip.number());
                return;
            }
            Err(e) => {
                debug!("Skip to mine new block due to error getting header, validator: {}, tip: {}, due to {}", self.validator_address, tip.number(), e);
                return;
            }
        };

        let parent_snapshot = match self.snapshot_provider.snapshot(tip.number()) {
            Some(snapshot) => snapshot,
            None => {
                debug!("Skip to mine new block due to no snapshot available, validator: {}, tip: {}", self.validator_address, tip.number());
                return;
            }
        };
        
        if !parent_snapshot.validators.contains(&self.validator_address) {
            debug!("Skip to mine new block due to not authorized, validator: {}, tip: {}", self.validator_address, tip.number());
            return;
        }
        
        if parent_snapshot.sign_recently(self.validator_address) {
            debug!("Skip to mine new block due to signed recently, validator: {}, tip: {}", self.validator_address, tip.number());
            return;
        }
        
        // TODO: remove it later, now just for easy to debug.
        if !parent_snapshot.is_inturn(self.validator_address) {
            debug!("Skip to produce due to is not inturn, validator: {}, tip: {}", self.validator_address, tip.number());
            return;
        }

        let mining_ctx = MiningContext {
            parent_header,
            parent_snapshot: Arc::new(parent_snapshot),
        };

        debug!("Queuing mining context, next_block: {}", tip.number() + 1);
        if let Err(e) = self.mining_queue_tx.send(mining_ctx) {
            error!("Failed to send mining context to queue due to {}", e);
        }
    }
}

/// MainWorkWorker responsible for processing mining tasks and block building,
/// submit the seal block to engine-tree and other peers.
pub struct MainWorkWorker<Pool, Provider> {
    validator_address: Address,
    pool: Pool,
    provider: Provider,
    chain_spec: Arc<crate::chainspec::BscChainSpec>,
    parlia: Arc<crate::consensus::parlia::Parlia<crate::chainspec::BscChainSpec>>,
    snapshot_provider: Arc<dyn SnapshotProvider + Send + Sync>,
    mining_queue_rx: mpsc::UnboundedReceiver<MiningContext>,
}

impl<Pool, Provider> MainWorkWorker<Pool, Provider>
where
    Pool: TransactionPool<Transaction: PoolTransaction<Consensus = TransactionSigned>>
        + Clone
        + 'static,
    Provider: HeaderProvider<Header = alloy_consensus::Header>
        + BlockNumReader
        + reth_provider::StateProviderFactory
        + CanonStateSubscriptions
        + Clone
        + Send
        + Sync
        + 'static,
{
    pub fn new(
        validator_address: Address,
        pool: Pool,
        provider: Provider,
        chain_spec: Arc<crate::chainspec::BscChainSpec>,
        parlia: Arc<crate::consensus::parlia::Parlia<crate::chainspec::BscChainSpec>>,
        snapshot_provider: Arc<dyn SnapshotProvider + Send + Sync>,
        mining_queue_rx: mpsc::UnboundedReceiver<MiningContext>,
    ) -> Self {
        Self {
            pool,
            provider,
            chain_spec,
            parlia,
            validator_address,
            snapshot_provider,
            mining_queue_rx,
        }
    }

    pub async fn run(mut self) {
        info!("Succeed to spawn main work worker, address: {}", self.validator_address);
        
        while let Some(mining_ctx) = self.mining_queue_rx.recv().await {
            let next_block = mining_ctx.parent_header.number() + 1;
            debug!("Received mining context, next_block: {}", next_block);

            match self.try_mine_block(mining_ctx).await {
                Ok(()) => {
                    debug!("Succeed to mine block or skipped gracefully, next_block: {}", next_block);
                }
                Err(e) => {
                    error!("Failed to mine block due to {}, next_block: {}", e, next_block);
                }
            }
        }
        
        warn!("Mining worker stopped");
    }

    async fn try_mine_block(
        &self,
        mining_ctx: MiningContext,
    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let attributes = prepare_new_attributes(
            self.parlia.clone(), 
            &mining_ctx.parent_snapshot, 
            &mining_ctx.parent_header, 
            self.validator_address
        );

        let evm_config = BscEvmConfig::new(self.chain_spec.clone());
        let payload_builder = BscPayloadBuilder::new(
            self.provider.clone(), 
            self.pool.clone(), 
            evm_config, 
            EthereumBuilderConfig::new()
        );
        let payload = match payload_builder.build_payload(
            BuildArguments::<EthPayloadBuilderAttributes, BscBuiltPayload>::new(
                reth_revm::cached::CachedReads::default(),
                PayloadConfig::new(Arc::new(mining_ctx.parent_header.clone()), attributes),
                CancelOnDrop::default(),
                None,)
        ) {
            Ok(p) => p,
            Err(e) => {
                let msg = e.to_string();
                // Gracefully skip if parent state is not (yet) available; this can happen
                // during rapid reorgs or concurrent imports timing.
                if msg.contains("no state found for block") {
                    debug!(
                        "Skip mining attempt due to missing parent state: {} (parent: 0x{:x})",
                        msg,
                        mining_ctx.parent_header.hash()
                    );
                    return Ok(());
                }
                return Err(e);
            }
        };
        info!("Start to submit block: {} (hash: 0x{:x}, txs: {})", 
            payload.block().header().number(),
            payload.block().hash(),
            payload.block().body().transaction_count()
        );

        self.submit_block(payload.block(), mining_ctx).await?;
        info!("Succeed to mine and submit, block: {}", payload.block().header().number());
        Ok(())
    }

    /// todo: check and refine.
    async fn submit_block(
        &self,
        sealed_block: &SealedBlock<BscBlock>,
        mining_ctx: MiningContext,
    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        // Validate the parent is still canonical and we're still eligible before submission.
        let parent_number = mining_ctx.parent_header.number();
        if let Ok(Some(latest_parent)) = self.provider.sealed_header(parent_number) {
            if latest_parent.hash_slow() != mining_ctx.parent_header.hash_slow() {
                tracing::debug!(
                    target: "bsc::miner",
                    expected_parent = %format!("0x{:x}", mining_ctx.parent_header.hash_slow()),
                    current_parent = %format!("0x{:x}", latest_parent.hash_slow()),
                    "Parent header changed before submission, dropping block"
                );
                return Ok(());
            }
        }

        if let Some(snap) = self.snapshot_provider.snapshot(parent_number) {
            // Drop if we're no longer authorized or over the recent-sign limit.
            if !snap.validators.contains(&self.validator_address) {
                tracing::debug!(
                    target: "bsc::miner",
                    validator = %format!("0x{:x}", self.validator_address),
                    "Not authorized anymore at parent, dropping block"
                );
                return Ok(());
            }
            if snap.sign_recently(self.validator_address) {
                tracing::debug!(
                    target: "bsc::miner",
                    validator = %format!("0x{:x}", self.validator_address),
                    block_number = parent_number + 1,
                    "Validator signed recently; dropping block to avoid over-limit"
                );
                return Ok(());
            }
            if !snap.is_inturn(self.validator_address) {
                tracing::debug!(
                    target: "bsc::miner",
                    validator = %format!("0x{:x}", self.validator_address),
                    block_number = parent_number + 1,
                    "No longer in turn; dropping block"
                );
                return Ok(());
            }
        }

        // now is focus on the basic workflow.
        // TODO: refine it later. https://github.com/bnb-chain/bsc/blob/master/consensus/parlia/parlia.go#L1702.
        let present_timestamp = self.parlia.present_timestamp();
        if sealed_block.header().timestamp > present_timestamp {
            let delay_ms = (sealed_block.header().timestamp - present_timestamp) * 1000;
            tracing::info!(
                target: "bsc::miner",
                block_number = sealed_block.header().number,
                block_timestamp = sealed_block.header().timestamp,
                present_timestamp = present_timestamp,
                delay_ms = delay_ms,
                "Block timestamp is in the future, waiting before submission"
            );
            tokio::time::sleep(tokio::time::Duration::from_millis(delay_ms)).await;
            tracing::debug!(
                target: "bsc::miner",
                block_number = sealed_block.header().number,
                "Finished waiting, proceeding with block submission"
            );

            // Re-validate after waiting since head/snapshot may have changed.
            if let Ok(Some(latest_parent)) = self.provider.sealed_header(parent_number) {
                if latest_parent.hash_slow() != mining_ctx.parent_header.hash_slow() {
                    tracing::debug!(
                        target: "bsc::miner",
                        expected_parent = %format!("0x{:x}", mining_ctx.parent_header.hash_slow()),
                        current_parent = %format!("0x{:x}", latest_parent.hash_slow()),
                        "Parent header changed during wait, dropping block"
                    );
                    return Ok(());
                }
            }

            if let Some(snap) = self.snapshot_provider.snapshot(parent_number) {
                if snap.sign_recently(self.validator_address) || !snap.is_inturn(self.validator_address) {
                    tracing::debug!(
                        target: "bsc::miner",
                        validator = %format!("0x{:x}", self.validator_address),
                        block_number = parent_number + 1,
                        "Eligibility changed during wait; dropping block"
                    );
                    return Ok(());
                }
            }
        }

        let parent_td = self.provider.header_td_by_number(parent_number)
            .map_err(|e| format!("Failed to get parent total difficulty due to {}", e))?
            .unwrap_or_default();
        let current_difficulty = sealed_block.header().difficulty();
        let new_td = parent_td + current_difficulty;
        
        let td = U128::from(new_td.to::<u128>());
        let block_hash = sealed_block.hash();
        let new_block = BscNewBlock(reth_eth_wire::NewBlock { block: sealed_block.clone_block(), td });
        let msg = NewBlockMessage { hash: block_hash, block: Arc::new(new_block) };

        if let Some(sender) = get_block_import_sender() {
            let peer_id = get_local_peer_id_or_default();
            let incoming: crate::node::network::block_import::service::IncomingBlock =
                (msg, peer_id);
            if sender.send(incoming).is_err() {
                warn!("Failed to send mined block to import service due to channel closed");
                return Err("Failed to send mined block to import service due to channel closed".into());
            } else {
                debug!("Succeed to send mined block to import service");
            }
        } else {
            warn!("Failed to send mined block due to import sender not initialised");
            return Err("Failed to send mined block due to import sender not initialised".into());
        }

        Ok(())
    }
}

/// Miner that handles block production for BSC.
pub struct BscMiner<Pool, Provider> {
    validator_address: Address,
    signing_key: SigningKey,
    task_executor: TaskExecutor,
    new_work_worker: NewWorkWorker<Provider>,
    main_work_worker: MainWorkWorker<Pool, Provider>,
}

impl<Pool, Provider> BscMiner<Pool, Provider>
where
    Pool: TransactionPool<Transaction: PoolTransaction<Consensus = TransactionSigned>>
        + Clone
        + 'static,
    Provider: HeaderProvider<Header = alloy_consensus::Header>
        + BlockNumReader
        + reth_provider::StateProviderFactory
        + CanonStateSubscriptions
        + Clone
        + Send
        + Sync
        + 'static,
{
    pub fn new(
        pool: Pool,
        provider: Provider,
        snapshot_provider: Arc<dyn SnapshotProvider + Send + Sync>,
        chain_spec: Arc<crate::chainspec::BscChainSpec>,
        mining_config: MiningConfig,
        task_executor: TaskExecutor,
    ) -> Result<Self, Box<dyn std::error::Error + Send + Sync>> {
        mining_config.validate()?;

        // We'll derive and trust the validator address from the configured signing key when possible.
        // If not available, fall back to configured address (may be ZERO when disabled).
        let mut validator_address = mining_config.validator_address.unwrap_or(Address::ZERO);
        let signing_key = if let Some(keystore_path) = &mining_config.keystore_path {
            let password = mining_config.keystore_password.as_deref().unwrap_or("");
            keystore::load_private_key_from_keystore(keystore_path, password)?
        } else if let Some(hex_key) = &mining_config.private_key_hex {
            keystore::load_private_key_from_hex(hex_key)?
        } else {
            return Err("No signing key configured".into());
        };
        // Derive validator address from the signing key and prefer it.
        let derived_address = keystore::get_validator_address(&signing_key);
        if derived_address != validator_address {
            if validator_address != Address::ZERO {
                warn!(
                    "Validator address mismatch, configured: {}, derived: {}",
                    validator_address, derived_address
                );
            }
            info!("Succeed to derived address from private key, address: {}", derived_address);
            validator_address = derived_address;
        }
        
        let (mining_queue_tx, mining_queue_rx) = mpsc::unbounded_channel::<MiningContext>();
        let new_work_worker = NewWorkWorker::new(
            validator_address,
            provider.clone(),
            snapshot_provider.clone(),
            mining_queue_tx.clone(),
        );
        let main_work_worker = MainWorkWorker::new(
            validator_address,
            pool.clone(),
            provider.clone(),
            chain_spec.clone(),
            Arc::new(crate::consensus::parlia::Parlia::new(chain_spec.clone(), 200)),
            snapshot_provider.clone(),
            mining_queue_rx,
        );
        
        let miner = Self {
            validator_address,
            signing_key,
            task_executor: task_executor.clone(),
            new_work_worker,
            main_work_worker,
        };
        info!("Succeed to new miner, address: {}", validator_address);
        Ok(miner)
    }

    pub async fn start(self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let private_key_bytes = self.signing_key.as_nonzero_scalar().to_bytes();
        let private_key = B256::from_slice(&private_key_bytes);
        if let Err(e) = init_global_signer(private_key) {
            return Err(format!("Failed to initialize global signer due to {}", e).into());
        } else {
            info!("Succeed to initialize global signer");
        }
        self.spawn_workers().await
    }

    async fn spawn_workers(self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        self.task_executor.spawn_critical("new_work_worker", self.new_work_worker.run());
        self.task_executor.spawn_critical("main_work_worker", self.main_work_worker.run());
        info!("Succeed to start mining, address: {}", self.validator_address);
        Ok(())
    }

}
